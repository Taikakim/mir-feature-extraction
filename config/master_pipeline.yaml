# Master Pipeline Configuration
# Copy this file and customize for your project
#
# Usage:
#   python src/master_pipeline.py --config config/my_project.yaml
#   python src/master_pipeline.py --config config/my_project.yaml --overwrite  # CLI overrides config

# =============================================================================
# PATHS
# =============================================================================
paths:
  input: /run/media/kim/LostLands/ai-music/Goa Dataset                    # Required: Input directory (raw audio or organized)
  output: /run/media/kim/LostLands/ai-music/Goa_Separated                  # Output directory for organized files (null = in-place)
  stems_source: null             # Pre-existing stems directory (skips Demucs if set)

# =============================================================================
# STAGE CONTROL
# =============================================================================
stages:
  organize: null                 # Stage 1: Organize raw files into project structure
  track_analysis: true           # Stage 2: Full track analysis (Demucs, beats, metadata)
  cropping: true                 # Stage 3: Create training crops
  crop_analysis: true            # Stage 4: Analyze crops (features + AI descriptions)

# =============================================================================
# SOURCE SEPARATION
# =============================================================================
source_separation:
  # Selected backend: 'demucs' or 'bs_roformer'
  # 'demucs' = fast, good general quality
  # 'bs_roformer' = slower but often cleaner vocals/instrumentals
  backend: bs_roformer

  # ---------------------------------------------------------------------------
  # BS-ROFORMER CONFIGURATION
  # ---------------------------------------------------------------------------
  bs_roformer:
    # Model name (directory name in models/)
    # Recommended: 'jarredou-BS-ROFO-SW-Fixed-drums' or 'SYH99999-bs_roformer_4stems_ft'
    model_name: jarredou-BS-ROFO-SW-Fixed-drums

    # Base directory for models
    model_dir: /home/kim/Projects/mir/models/bs-roformer

    # Batch size (1 is most memory efficient and often fastest on consumer GPUs)
    batch_size: 2

    device: cuda

  # ---------------------------------------------------------------------------
  # DEMUCS CONFIGURATION
  # ---------------------------------------------------------------------------
  demucs:
    # Available users: htdemucs, htdemucs_ft, htdemucs_6s, mdx_extra
    model: htdemucs                # Default: htdemucs (good balance of speed/quality)

    shifts: 0                      # Random shifts (0=fast for MIR, 1+=hifi quality)
    device: cuda                   # cuda, cpu, mps

    # Segment length in seconds - controls GPU memory usage
    # Set to null to use model's default (recommended)
    segment: null

    output_format: mp3             # mp3 (default, VBR), flac, wav, wav24, wav32, ogg
    mp3_bitrate: 128               # MP3 bitrate (64-320) if format=mp3
    clip_mode: rescale             # rescale or clamp

    # Parallel processing (subprocess-based, each worker ~5GB VRAM)
    workers: 4                     # Parallel workers for batch processing

# =============================================================================
# RHYTHM ANALYSIS
# =============================================================================
rhythm:
  # Beat detection uses madmom by default
  # These features are extracted for full tracks and migrated to crops
  enabled: true
  workers: 11                     # Parallel workers for beat/downbeat detection

# =============================================================================
# CROPPING
# =============================================================================
cropping:
  length_samples: 524288         # Crop length in SAMPLES (2097152 = ~47.5s at 44.1kHz)
                                 # Common values:
                                 #   1323000  = ~30.0s at 44.1kHz
                                 #   2097152  = ~47.5s at 44.1kHz (default)
                                 #   2646000  = ~60.0s at 44.1kHz

  mode: beat-aligned               # sequential or beat-aligned
  overlap: false                 # 50% overlap between crops
  div4: false                    # Ensure downbeats divisible by 4 (beat-aligned mode)
  include_stems: true            # Also crop stems alongside full mix
  workers: 1                     # Parallel workers for cropping

# =============================================================================
# FEATURE EXTRACTION
# =============================================================================
features:
  # Loudness (LUFS/LRA)
  loudness: true

  # Spectral features (flatness, flux, skewness, kurtosis)
  spectral: true

  # Multiband RMS (bass, body, mid, air)
  multiband_rms: true

  # Harmonic/Chroma (12-bin pitch class)
  chroma: true

  # Timbral (Audio Commons: brightness, roughness, hardness, etc.)
  timbral: true

  # Essentia classification
  essentia: true
  essentia_genre: true         # Genre classification (400 Discogs classes)
  essentia_mood: true          # Mood/theme classification (56 classes)
  essentia_instrument: true    # Instrument detection (40 classes)
  essentia_voice: true         # Voice vs instrumental probability
  essentia_gender: true        # Vocal gender (requires vocals stem with meaningful content)

# Vocal content detection thresholds (for gender analysis)
# A vocal track is considered empty/meaningless if ALL conditions are true:
#   crest_factor > vocal_crest_threshold AND rms < vocal_rms_threshold AND peak < vocal_peak_threshold
vocal_content:
  crest_factor_threshold: 30.0   # dB - crest factor above this suggests sparse/impulsive signal
  rms_threshold: -42.0           # dBFS - RMS below this suggests very quiet content
  peak_threshold: -20.0          # dBFS - peak below this suggests no meaningful signal

  # AudioBox aesthetics (content enjoyment, production quality, etc.)
  audiobox: true

  # Per-stem features (requires stems)
  per_stem: true

# =============================================================================
# PER-FEATURE OVERWRITE CONTROL
# =============================================================================
# By default, existing features are NOT overwritten. Set individual keys to true
# to force regeneration of specific features even if they already exist.
# These override the global processing.overwrite setting.
overwrite:
  demucs: false                  # Overwrite existing stem separations (legacy key)
  source_separation: false       # Overwrite existing stem separations
  beats: false                   # Overwrite existing beat grids
  bpm: false                     # Overwrite existing BPM data
  crops: false                   # Overwrite existing training crops
  loudness: false                # Overwrite existing loudness data
  spectral: false                # Overwrite existing spectral features
  multiband_rms: false           # Overwrite existing multiband RMS data
  chroma: true                   # Overwrite existing chroma features
  timbral: false                 # Overwrite existing timbral features
  essentia: false                # Overwrite existing Essentia classification
  audiobox: false                # Overwrite existing AudioBox aesthetics
  per_stem_rhythm: false         # Overwrite existing per-stem rhythm features
  per_stem_harmonic: false       # Overwrite existing per-stem harmonic features
  music_flamingo: false          # Overwrite existing AI descriptions
  metadata: false                # Overwrite existing metadata lookups

# =============================================================================
# MUSIC FLAMINGO (AI Descriptions)
# =============================================================================
music_flamingo:
  enabled: true
  model: Q8_0                    # IQ3_M (fast), Q6_K (balanced), Q8_0 (best quality)
  context_size: 16384             # LLM context window (1024-2048 plenty for descriptions)
                                 # Lower = less VRAM. Audio is pre-encoded, not in context.

  # Prompt types to generate (define as "key: prompt text")
  # {genres} is interpolated from essentia_genre in .INFO at runtime
  prompts:
    full: "The genre is {genres}. Describe the track in detail: the mood, timbre, genre, instrumentation, production aesthetics and techniques, construction. Do not use filler words, be professional, do not hallucinate. It's better to say nothing than stretch the truth."

  # Max tokens per prompt type (higher = longer descriptions, more VRAM)
  max_tokens:
    full: 768

  # Granite revision: condense MF output into shorter focused descriptions
  # Each key under prompts → music_flamingo_{key} in .INFO
  revision:
    enabled: true
    model: models/LMM/granite-4.0-h-tiny-GGUF/granite-4.0-h-tiny-Q8_0.gguf
    max_tokens: 512
    temperature: 0.7
    n_ctx: 4096
    prompts:
      short_technical: "A brief technical description of production and mixing (20-30 words)"
      short_mood: "The mood and emotional character (10-20 words)"
      short_genre: "A general description of the track (5-15 words)"

# =============================================================================
# METADATA LOOKUP
# =============================================================================
# Priority order for artist identification:
#   1. ID3 tags (if valid artist exists, no fingerprinting needed)
#   2. Folder name (if valid artist exists, no fingerprinting needed)  
#   3. AcoustID fingerprinting (ONLY as last resort when both above fail)
metadata:
  enabled: true
  use_spotify: false              # Set to false to skip Spotify (e.g., during rate limit cooldown)
  use_musicbrainz: true          # Set to false to skip MusicBrainz
  use_fingerprinting: true       # Enable AcoustID fingerprinting as LAST RESORT only
                                 # (only used when ID3 tags AND folder name lack valid artist)
  fix_various_artists: true      # Fix "Various Artists" names during file organization
                                 # Uses ID3 tags first, then Spotify/MusicBrainz lookup

  # Artists that trigger metadata lookup (case-insensitive)
  various_artists_aliases:
    - various artists
    - various
    - va
    - v/a
    - v.a.
    - compilation
    - unknown artist
    - unknown

# =============================================================================
# STEM QUALITY FILTERING
# =============================================================================
stem_quality:
  enabled: false                   # When true, auto-mix flagged stems back to 'other'
  crest_factor_threshold: -40      # dB — crest factor below this = flat/noisy
  rms_threshold: -39               # dBFS — RMS below this = near-silence
  peak_threshold: -20              # dBFS — peak below this = very quiet
                                   # A stem is flagged when ALL THREE are met (AND)

# =============================================================================
# VOCAL REMOVAL (Instrumental Output)
# =============================================================================
vocal_removal:
  enabled: false                   # Remove vocals from full_mix before cropping
  method: auto                     # 'auto' = uses separation backend:
                                   #   Demucs:      sums drums+bass+other
                                   #   BS-RoFormer: subtracts vocal stem from full_mix
                                   # 'invert' = always subtract vocal stem

# =============================================================================
# FILENAME CLEANUP
# =============================================================================
filename_cleanup:
  enabled: true                  # Clean filenames for T5 tokenizer compatibility
                                 # Converts accented chars to ASCII, normalizes spaces/dashes

# =============================================================================
# ROCM / GPU ENVIRONMENT
# =============================================================================
# These are applied by src/core/rocm_env.py before torch is imported.
# Shell exports take precedence (os.environ.setdefault never overwrites).
# Kept here as the canonical reference for the project.
rocm:
  # Flash Attention 2 via Triton (AMD)
  FLASH_ATTENTION_TRITON_AMD_ENABLE: "TRUE"

  # TunableOp — pre-tuned GEMM kernels for RDNA4
  # TUNING=1 generates new kernels (slow first run); 0 reuses cached results
  PYTORCH_TUNABLEOP_ENABLED: "1"
  PYTORCH_TUNABLEOP_TUNING: "1"
  PYTORCH_TUNABLEOP_VERBOSE: "1"

  # HIP memory management
  # garbage_collection_threshold frees unused blocks; max_split_size_mb caps allocation chunks
  PYTORCH_HIP_ALLOC_CONF: "garbage_collection_threshold:0.8,max_split_size_mb:512"
  # Release cached blocks when free VRAM falls below this (helps prevent OOM)
  PYTORCH_HIP_FREE_MEMORY_THRESHOLD_MB: "256"

  # Prevent common AMD CPU/GPU desync performance bug
  HIP_FORCE_DEV_KERNARG: "1"

  # torch.compile is buggy with Flash Attention on RDNA — keep disabled
  TORCH_COMPILE: "0"

  # CPU thread count
  OMP_NUM_THREADS: "8"

  MIOPEN_FIND_MODE: "3"
  # MIOPEN_FIND_MODE: disabled — causes VAE freezes on some workloads
  # Set to 2 (NORMAL) or 3 (EXHAUSTIVE) in shell if needed for specific scripts

# =============================================================================
# PROCESSING OPTIONS
# =============================================================================
processing:
  device: cuda                   # cuda or cpu
  overwrite: false               # Overwrite existing features
  verbose: false                 # Verbose logging
  feature_workers: 10             # Parallel workers for CPU features (loudness, spectral, timbral, etc.)
  essentia_workers: 6            # Separate limit for Essentia (TensorFlow deadlocks with >4-6 workers)
