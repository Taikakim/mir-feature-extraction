# Master Pipeline Configuration
# Copy this file and customize for your project
#
# Usage:
#   python src/master_pipeline.py --config config/my_project.yaml
#   python src/master_pipeline.py --config config/my_project.yaml --overwrite  # CLI overrides config

# =============================================================================
# PATHS
# =============================================================================
paths:
  input: /run/media/kim/e2b6d8bb-c062-4d44-9f21-40d0eb277696/00ai/01test                    # Required: Input directory (raw audio or organized)
  output: /run/media/kim/e2b6d8bb-c062-4d44-9f21-40d0eb277696/00ai/01test-separated                # Output directory for organized files (null = in-place)
  stems_source: null             # Pre-existing stems directory (skips Demucs if set)

# =============================================================================
# STAGE CONTROL
# =============================================================================
stages:
  organize: true                 # Stage 1: Organize raw files into project structure
  track_analysis: true           # Stage 2: Full track analysis (Demucs, beats, metadata)
  cropping: true                 # Stage 3: Create training crops
  crop_analysis: true            # Stage 4: Analyze crops (features + AI descriptions)

# =============================================================================
# SOURCE SEPARATION
# =============================================================================
source_separation:
  # Selected backend: 'demucs' or 'bs_roformer'
  # 'demucs' = fast, good general quality
  # 'bs_roformer' = slower but often cleaner vocals/instrumentals
  backend: bs_roformer

  # ---------------------------------------------------------------------------
  # BS-ROFORMER CONFIGURATION
  # ---------------------------------------------------------------------------
  bs_roformer:
    # Model name (directory name in models/)
    # Recommended: 'jarredou-BS-ROFO-SW-Fixed-drums' or 'SYH99999-bs_roformer_4stems_ft'
    model_name: jarredou-BS-ROFO-SW-Fixed-drums

    # Base directory for models
    model_dir: /home/kim/Projects/mir/models/bs-roformer

    # Batch size (1 is most memory efficient and often fastest on consumer GPUs)
    batch_size: 1

    device: cuda

  # ---------------------------------------------------------------------------
  # DEMUCS CONFIGURATION
  # ---------------------------------------------------------------------------
  demucs:
    # Available users: htdemucs, htdemucs_ft, htdemucs_6s, mdx_extra
    model: htdemucs                # Default: htdemucs (good balance of speed/quality)

    shifts: 0                      # Random shifts (0=fast for MIR, 1+=hifi quality)
    device: cuda                   # cuda, cpu, mps

    # Segment length in seconds - controls GPU memory usage
    # Set to null to use model's default (recommended)
    segment: null

    output_format: mp3             # mp3 (default, VBR), flac, wav, wav24, wav32, ogg
    mp3_bitrate: 128               # MP3 bitrate (64-320) if format=mp3
    clip_mode: rescale             # rescale or clamp

    # Parallel processing (subprocess-based, each worker ~5GB VRAM)
    workers: 4                     # Parallel workers for batch processing

# =============================================================================
# RHYTHM ANALYSIS
# =============================================================================
rhythm:
  # Beat detection uses madmom by default
  # These features are extracted for full tracks and migrated to crops
  enabled: true
  workers: 8                     # Parallel workers for beat/downbeat detection

# =============================================================================
# CROPPING
# =============================================================================
cropping:
  length_samples: 524288         # Crop length in SAMPLES (2097152 = ~47.5s at 44.1kHz)
                                 # Common values:
                                 #   1323000  = ~30.0s at 44.1kHz
                                 #   2097152  = ~47.5s at 44.1kHz (default)
                                 #   2646000  = ~60.0s at 44.1kHz

  mode: beat-aligned               # sequential or beat-aligned
  overlap: false                 # 50% overlap between crops
  div4: false                    # Ensure downbeats divisible by 4 (beat-aligned mode)
  include_stems: true            # Also crop stems alongside full mix
  workers: 12                     # Parallel workers for cropping

# =============================================================================
# FEATURE EXTRACTION
# =============================================================================
features:
  # Loudness (LUFS/LRA)
  loudness: true

  # Spectral features (flatness, flux, skewness, kurtosis)
  spectral: true

  # Multiband RMS (bass, body, mid, air)
  multiband_rms: true

  # Harmonic/Chroma (12-bin pitch class)
  chroma: true

  # Timbral (Audio Commons: brightness, roughness, hardness, etc.)
  timbral: true

  # Essentia classification (danceability, genre, mood, instruments)
  essentia: true

  # AudioBox aesthetics (content enjoyment, production quality, etc.)
  audiobox: true

  # Per-stem features (requires stems)
  per_stem: true

# =============================================================================
# PER-FEATURE OVERWRITE CONTROL
# =============================================================================
# By default, existing features are NOT overwritten. Set individual keys to true
# to force regeneration of specific features even if they already exist.
# These override the global processing.overwrite setting.
overwrite:
  demucs: false                  # Overwrite existing stem separations (legacy key)
  source_separation: false       # Overwrite existing stem separations
  beats: false                   # Overwrite existing beat grids
  bpm: false                     # Overwrite existing BPM data
  crops: false                   # Overwrite existing training crops
  loudness: false                # Overwrite existing loudness data
  spectral: false                # Overwrite existing spectral features
  multiband_rms: false           # Overwrite existing multiband RMS data
  chroma: false                  # Overwrite existing chroma features
  timbral: false                 # Overwrite existing timbral features
  essentia: false                # Overwrite existing Essentia classification
  audiobox: false                # Overwrite existing AudioBox aesthetics
  per_stem_rhythm: false         # Overwrite existing per-stem rhythm features
  per_stem_harmonic: false       # Overwrite existing per-stem harmonic features
  music_flamingo: false          # Overwrite existing AI descriptions
  metadata: false                # Overwrite existing metadata lookups

# =============================================================================
# MUSIC FLAMINGO (AI Descriptions)
# =============================================================================
music_flamingo:
  enabled: true
  model: Q8_0                    # IQ3_M (fast), Q6_K (balanced), Q8_0 (best quality)
  context_size: 16384             # LLM context window (1024-2048 plenty for descriptions)
                                 # Lower = less VRAM. Audio is pre-encoded, not in context.

  # Prompt types to generate (all enabled by default)
  # Prompt types to generate (define as "key: prompt text")
  # You can add your own custom keys here.
  prompts:
    brief: "Describe this track in one sentence."
    technical: "explain the textures, dynamics and prominent production aesthetics. Keep the description compact, under 30 words"
    genre_mood_inst: "Brief description suitable for an AI inference prompt: What is the genre, mood and instrumentation of this music? Be specific about subgenres and describe the emotional character. Try to keep the description under 30 words."
    instrumentation: "Very brief description about the timbre and recognised instruments. What instruments and sounds are present in this track? Try to keep the description under 15 words"
    very_brief: "Describe the piece in less than six words"

  # Max tokens per prompt type (higher = longer descriptions, more VRAM)
  max_tokens:
    full: 256
    technical: 128
    genre_mood: 128
    instrumentation: 128
    structure: 128

# =============================================================================
# METADATA LOOKUP
# =============================================================================
# Priority order for artist identification:
#   1. ID3 tags (if valid artist exists, no fingerprinting needed)
#   2. Folder name (if valid artist exists, no fingerprinting needed)  
#   3. AcoustID fingerprinting (ONLY as last resort when both above fail)
metadata:
  enabled: true
  use_fingerprinting: true       # Enable AcoustID fingerprinting as LAST RESORT only
                                 # (only used when ID3 tags AND folder name lack valid artist)
  fix_various_artists: true      # Fix "Various Artists" names during file organization
                                 # Uses ID3 tags first, then Spotify/MusicBrainz lookup

  # Artists that trigger metadata lookup (case-insensitive)
  various_artists_aliases:
    - various artists
    - various
    - va
    - v/a
    - v.a.
    - compilation
    - unknown artist
    - unknown

# =============================================================================
# FILENAME CLEANUP
# =============================================================================
filename_cleanup:
  enabled: true                  # Clean filenames for T5 tokenizer compatibility
                                 # Converts accented chars to ASCII, normalizes spaces/dashes

# =============================================================================
# ROCM / GPU ENVIRONMENT
# =============================================================================
# These are applied by src/core/rocm_env.py before torch is imported.
# Shell exports take precedence (os.environ.setdefault never overwrites).
# Kept here as the canonical reference for the project.
rocm:
  # Flash Attention 2 via Triton (AMD)
  FLASH_ATTENTION_TRITON_AMD_ENABLE: "TRUE"

  # TunableOp — pre-tuned GEMM kernels for RDNA4
  # TUNING=1 generates new kernels (slow first run); 0 reuses cached results
  PYTORCH_TUNABLEOP_ENABLED: "1"
  PYTORCH_TUNABLEOP_TUNING: "1"
  PYTORCH_TUNABLEOP_VERBOSE: "1"

  # HIP memory management
  # garbage_collection_threshold frees unused blocks; max_split_size_mb caps allocation chunks
  PYTORCH_HIP_ALLOC_CONF: "garbage_collection_threshold:0.8,max_split_size_mb:512"
  # Release cached blocks when free VRAM falls below this (helps prevent OOM)
  PYTORCH_HIP_FREE_MEMORY_THRESHOLD_MB: "256"

  # Prevent common AMD CPU/GPU desync performance bug
  HIP_FORCE_DEV_KERNARG: "1"

  # torch.compile is buggy with Flash Attention on RDNA — keep disabled
  TORCH_COMPILE: "0"

  # CPU thread count
  OMP_NUM_THREADS: "10"

  MIOPEN_FIND_MODE: "2"
  # MIOPEN_FIND_MODE: disabled — causes VAE freezes on some workloads
  # Set to 2 (NORMAL) or 3 (EXHAUSTIVE) in shell if needed for specific scripts

# =============================================================================
# PROCESSING OPTIONS
# =============================================================================
processing:
  device: cuda                   # cuda or cpu
  overwrite: false               # Overwrite existing features
  verbose: false                 # Verbose logging
  feature_workers: 10             # Parallel workers for CPU features (loudness, spectral, timbral, etc.)
  essentia_workers: 4            # Separate limit for Essentia (TensorFlow deadlocks with >4-6 workers)
